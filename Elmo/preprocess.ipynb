{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from bilm import dump_token_embeddings\n",
    "# 数据预处理的类，生成训练集和测试集\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, config):\n",
    "        self._dataSource = config.dataSource\n",
    "        self._stopWordSource = config.stopWordSource\n",
    "        self._optionFile = config.optionFile\n",
    "        self._weightFile = config.weightFile\n",
    "        self._vocabFile = config.vocabFile\n",
    "        self._tokenEmbeddingFile = config.tokenEmbeddingFile\n",
    "\n",
    "        self._sequenceLength = config.sequenceLength  # 每条输入的序列处理为定长\n",
    "        self._embeddingSize = config.model.embeddingSize\n",
    "        self._batchSize = config.batchSize\n",
    "        self._rate = config.rate\n",
    "\n",
    "        self.trainReviews = []\n",
    "        self.trainLabels = []\n",
    "\n",
    "        self.evalReviews = []\n",
    "        self.evalLabels = []\n",
    "\n",
    "    def _readData(self, filePath):\n",
    "        \"\"\"\n",
    "        从csv文件中读取数据集\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(filePath)\n",
    "        labels = df[\"sentiment\"].tolist()\n",
    "        review = df[\"review\"].tolist()\n",
    "        reviews = [line.strip().split() for line in review]\n",
    "\n",
    "        return reviews, labels\n",
    "\n",
    "    def _genVocabFile(self, reviews):\n",
    "        \"\"\"\n",
    "        用我们的训练数据生成一个词汇文件，并加入三个特殊字符\n",
    "        \"\"\"\n",
    "        allWords = [word for review in reviews for word in review]\n",
    "        wordCount = Counter(allWords)  # 统计词频\n",
    "        sortWordCount = sorted(wordCount.items(), key=lambda x: x[1], reverse=True)\n",
    "        words = [item[0] for item in sortWordCount]\n",
    "        allTokens = ['<S>', '</S>', '<UNK>'] + words\n",
    "        with open(self._vocabFile, 'w') as fout:\n",
    "            fout.write('\\n'.join(allTokens))\n",
    "\n",
    "    def _fixedSeq(self, reviews):\n",
    "        \"\"\"\n",
    "        将长度超过200的截断为200的长度\n",
    "        \"\"\"\n",
    "        return [review[:self._sequenceLength] for review in reviews]\n",
    "\n",
    "    def _genElmoEmbedding(self):\n",
    "        \"\"\"\n",
    "        调用ELMO源码中的dump_token_embeddings方法，基于字符的表示生成词的向量表示。并保存成hdf5文件，文件中的\"embedding\"键对应的value就是\n",
    "        词汇表文件中各词汇的向量表示，这些词汇的向量表示之后会作为BiLM的初始化输入。\n",
    "        \"\"\"\n",
    "        dump_token_embeddings(\n",
    "            self._vocabFile, self._optionFile, self._weightFile, self._tokenEmbeddingFile)\n",
    "\n",
    "    def _genTrainEvalData(self, x, y, rate):\n",
    "        \"\"\"\n",
    "        生成训练集和验证集\n",
    "        \"\"\"\n",
    "        y = [[item] for item in y]\n",
    "        trainIndex = int(len(x) * rate)\n",
    "\n",
    "        trainReviews = x[:trainIndex]\n",
    "        trainLabels = y[:trainIndex]\n",
    "\n",
    "        evalReviews = x[trainIndex:]\n",
    "        evalLabels = y[trainIndex:]\n",
    "\n",
    "        return trainReviews, trainLabels, evalReviews, evalLabels\n",
    "\n",
    "    def dataGen(self):\n",
    "        \"\"\"\n",
    "        初始化训练集和验证集\n",
    "        \"\"\"\n",
    "\n",
    "        # 初始化数据集\n",
    "        reviews, labels = self._readData(self._dataSource)\n",
    "\n",
    "        #         self._genVocabFile(reviews) # 生成vocabFile\n",
    "        #         self._genElmoEmbedding()  # 生成elmo_token_embedding\n",
    "\n",
    "        reviews = self._fixedSeq(reviews)\n",
    "\n",
    "        # 初始化训练集和测试集\n",
    "        trainReviews, trainLabels, evalReviews, evalLabels = self._genTrainEvalData(reviews, labels, self._rate)\n",
    "        self.trainReviews = trainReviews\n",
    "        self.trainLabels = trainLabels\n",
    "\n",
    "        self.evalReviews = evalReviews\n",
    "        self.evalLabels = evalLabels\n",
    "\n",
    "\n",
    "# 输出batch数据集\n",
    "def nextBatch(x, y, batchSize):\n",
    "        \"\"\"\n",
    "        生成batch数据集，用生成器的方式输出\n",
    "        \"\"\"\n",
    "        # 每一个epoch时，都要打乱数据集\n",
    "        midVal = list(zip(x, y))\n",
    "        random.shuffle(midVal)\n",
    "        x, y = zip(*midVal)\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "\n",
    "        numBatches = len(x) // batchSize\n",
    "\n",
    "        for i in range(numBatches):\n",
    "            start = i * batchSize\n",
    "            end = start + batchSize\n",
    "            batchX =x[start: end]\n",
    "            batchY = y[start: end]\n",
    "\n",
    "            yield batchX, batchY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "pycharm-3464d5c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
