{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模式的demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\SYX\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.919 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入词典\n",
    "     自定义词典\n",
    "     jieba,oad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八一双鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉赏鉴/”/的/标题/，/在/自定义/词库/中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n",
      "========================================\n",
      "李小福 / nr ,  是 / v ,  创新办 / i ,  主任 / b ,  也 / d ,  是 / v ,  云计算 / x ,  方面 / n ,  的 / uj ,  专家 / n ,  ; / x ,    / x ,  什么 / r ,  是 / v ,  八一双鹿 / nz ,  \n",
      " / x ,  例如 / v ,  我 / r ,  输入 / v ,  一个 / m ,  带 / v ,  “ / x ,  韩玉赏鉴 / nz ,  ” / x ,  的 / uj ,  标题 / n ,  ， / x ,  在 / p ,  自定义 / l ,  词库 / n ,  中 / f ,  也 / d ,  增加 / v ,  了 / ul ,  此 / r ,  词 / n ,  为 / p ,  N / eng ,  类 / q ,  \n",
      " / x ,  「 / x ,  台中 / s ,  」 / x ,  正確 / ad ,  應該 / v ,  不 / d ,  會 / v ,  被 / p ,  切開 / ad ,  。 / x ,  mac / eng ,  上 / f ,  可 / v ,  分出 / v ,  「 / x ,  石墨烯 / x ,  」 / x ,  ； / x ,  此時 / c ,  又 / d ,  可以 / c ,  分出 / v ,  來 / zg ,  凱特琳 / nz ,  了 / ul ,  。 / x ,  \n",
      "========================================\n",
      "easy_install/ /is/ /great\n",
      "python/ /的/正则表达式/是/好用/的\n",
      "========================================\n",
      "今天天气/不错\n",
      "今天天气 Before: 3, After: 0\n",
      "今天/天气/不错\n",
      "如果/放到/post/中将/出错/。\n",
      "中将 Before: 763, After: 494\n",
      "如果/放到/post/中/将/出错/。\n",
      "我们/中/出/了/一个/叛徒\n",
      "中出 Before: 3, After: 3\n",
      "我们/中/出/了/一个/叛徒\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "from __future__ import print_function, unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"userdict.txt\")\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))\n",
    "\n",
    "print(\"=\"*40)\n",
    "\n",
    "result = pseg.cut(test_sent)\n",
    "\n",
    "for w in result:\n",
    "    print(w.word, \"/\", w.flag, \", \", end=' ')\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "\n",
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 TF-IDF 算法的关键词抽取\n",
    "\n",
    "    import jieba.analyse\n",
    "    jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "        sentence 为待提取的文本\n",
    "        topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "        withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "        allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "    jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "欧亚 0.7300142700289363\n",
      "吉林 0.659038184373617\n",
      "置业 0.4887134522112766\n",
      "万元 0.3392722481859574\n",
      "增资 0.33582401985234045\n",
      "4.3 0.25435675538085106\n",
      "7000 0.25435675538085106\n",
      "2013 0.25435675538085106\n",
      "139.13 0.25435675538085106\n",
      "实现 0.19900979900382978\n",
      "综合体 0.19480309624702127\n",
      "经营范围 0.19389757253595744\n",
      "亿元 0.1914421623587234\n",
      "在建 0.17541884768425534\n",
      "全资 0.17180164988510638\n",
      "注册资本 0.1712441526\n",
      "百货 0.16734460041382979\n",
      "零售 0.1475057117057447\n",
      "子公司 0.14596045237787234\n",
      "营业 0.13920178509021275\n"
     ]
    }
   ],
   "source": [
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 TextRank 算法的关键词抽取\n",
    "\n",
    "    jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。\n",
    "    jieba.analyse.TextRank() 新建自定义 TextRank 实例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TextRank\n",
      "----------------------------------------\n",
      "吉林 1.0\n",
      "欧亚 0.9966893354178172\n",
      "置业 0.6434360313092776\n",
      "实现 0.5898606692859626\n",
      "收入 0.43677859947991454\n",
      "增资 0.4099900531283276\n",
      "子公司 0.35678295947672795\n",
      "城市 0.34971383667403655\n",
      "商业 0.34817220716026936\n",
      "业务 0.3092230992619838\n",
      "在建 0.3077929164033088\n",
      "营业 0.3035777049319588\n",
      "全资 0.303540981053475\n",
      "综合体 0.29580869172394825\n",
      "注册资本 0.29000519464085045\n",
      "有限公司 0.2807830798576574\n",
      "零售 0.27883620861218145\n",
      "百货 0.2781657628445476\n",
      "开发 0.2693488779295851\n",
      "经营范围 0.2642762173558316\n"
     ]
    }
   ],
   "source": [
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "     print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize\n",
    "    返回词语在原文的起止位置\n",
    "    默认模式demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "1. 分词\n",
      "----------------------------------------\n",
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n",
      "========================================\n",
      "2. 添加自定义词典/调整词典\n",
      "----------------------------------------\n",
      "如果/放到/post/中/将/出错/。\n",
      "494\n",
      "如果/放到/post/中/将/出错/。\n",
      "「/台中/」/正确/应该/不会/被/切开\n",
      "71\n",
      "「/台中/」/正确/应该/不会/被/切开\n",
      "========================================\n",
      "3. 关键词提取\n",
      "----------------------------------------\n",
      " TF-IDF\n",
      "----------------------------------------\n",
      "欧亚 0.7300142700289363\n",
      "吉林 0.659038184373617\n",
      "置业 0.4887134522112766\n",
      "万元 0.3392722481859574\n",
      "增资 0.33582401985234045\n",
      "4.3 0.25435675538085106\n",
      "7000 0.25435675538085106\n",
      "2013 0.25435675538085106\n",
      "139.13 0.25435675538085106\n",
      "实现 0.19900979900382978\n",
      "综合体 0.19480309624702127\n",
      "经营范围 0.19389757253595744\n",
      "亿元 0.1914421623587234\n",
      "在建 0.17541884768425534\n",
      "全资 0.17180164988510638\n",
      "注册资本 0.1712441526\n",
      "百货 0.16734460041382979\n",
      "零售 0.1475057117057447\n",
      "子公司 0.14596045237787234\n",
      "营业 0.13920178509021275\n",
      "----------------------------------------\n",
      " TextRank\n",
      "----------------------------------------\n",
      "吉林 1.0\n",
      "欧亚 0.9966893354178172\n",
      "置业 0.6434360313092776\n",
      "实现 0.5898606692859626\n",
      "收入 0.43677859947991454\n",
      "增资 0.4099900531283276\n",
      "子公司 0.35678295947672795\n",
      "城市 0.34971383667403655\n",
      "商业 0.34817220716026936\n",
      "业务 0.3092230992619838\n",
      "在建 0.3077929164033088\n",
      "营业 0.3035777049319588\n",
      "全资 0.303540981053475\n",
      "综合体 0.29580869172394825\n",
      "注册资本 0.29000519464085045\n",
      "有限公司 0.2807830798576574\n",
      "零售 0.27883620861218145\n",
      "百货 0.2781657628445476\n",
      "开发 0.2693488779295851\n",
      "经营范围 0.2642762173558316\n",
      "========================================\n",
      "4. 词性标注\n",
      "----------------------------------------\n",
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n",
      "========================================\n",
      "6. Tokenize: 返回词语在原文的起止位置\n",
      "----------------------------------------\n",
      " 默认模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n",
      "----------------------------------------\n",
      " 搜索模式\n",
      "----------------------------------------\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "from __future__ import unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import jieba.analyse\n",
    "\n",
    "print('='*40)\n",
    "print('1. 分词')\n",
    "print('-'*40)\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 默认模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "print('='*40)\n",
    "print('2. 添加自定义词典/调整词典')\n",
    "print('-'*40)\n",
    "\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中将/出错/。\n",
    "print(jieba.suggest_freq(('中', '将'), True))\n",
    "#494\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中/将/出错/。\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台/中/」/正确/应该/不会/被/切开\n",
    "print(jieba.suggest_freq('台中', True))\n",
    "#69\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台中/」/正确/应该/不会/被/切开\n",
    "\n",
    "print('='*40)\n",
    "print('3. 关键词提取')\n",
    "print('-'*40)\n",
    "print(' TF-IDF')\n",
    "print('-'*40)\n",
    "\n",
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n",
    "\n",
    "print('-'*40)\n",
    "print(' TextRank')\n",
    "print('-'*40)\n",
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print('%s %s' % (x, w))\n",
    "\n",
    "print('='*40)\n",
    "print('4. 词性标注')\n",
    "print('-'*40)\n",
    "\n",
    "words = jieba.posseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))\n",
    "\n",
    "print('='*40)\n",
    "print('6. Tokenize: 返回词语在原文的起止位置')\n",
    "print('-'*40)\n",
    "print(' 默认模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize('永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))\n",
    "\n",
    "print('-'*40)\n",
    "print(' 搜索模式')\n",
    "print('-'*40)\n",
    "\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "pycharm-3464d5c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
